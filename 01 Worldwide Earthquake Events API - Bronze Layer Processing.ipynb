{"cells":[{"cell_type":"markdown","source":["### Worldwide Earthquake Events API - Bronze Layer Processing"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d914f704-468a-47b9-8e20-e608cb0f73ec"},{"cell_type":"markdown","source":["****"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2b8876ef-0e8e-4ced-9171-25eea1996879"},{"cell_type":"code","source":["import requests\n","import json\n","\n","# Constructing the API URL with start and end dates provided by Data Factory, formatted for geojson output.\n","url = f\"https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime={start_date}&endtime={end_date}\"\n","\n","# Make the GET request to fetch the data\n","response = requests.get(url)\n","\n","# Check if the request was successful\n","if response.status_code == 200:\n","    #Get the JSON response\n","    data = response.json()\n","    data = data['features']\n","\n","    # Specify the file name and path\n","    file_path = f'/lakehouse/default/Files/{start_date}_earthquake_data.json'\n","\n","    with open(file_path, 'w') as file:\n","        # The `json.dump` method serializes `data` as a JSON formatted stream to `file`\n","        # `indent=4` makes the file human-readable by adding whitespace\n","        json.dump(data, file, indent=4)\n","\n","    print(f\"Data successfully saved to {file_path}\")\n","else:\n","    print(\"Failed to fetch data. Status code:\", response.status_code)\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":8,"statement_ids":[8],"state":"finished","livy_statement_state":"available","session_id":"30d65c52-cdfb-4f6f-a705-6779cd0f2222","normalized_state":"finished","queued_time":"2025-02-25T23:06:32.5907444Z","session_start_time":null,"execution_start_time":"2025-02-25T23:06:32.8077371Z","execution_finish_time":"2025-02-25T23:06:35.2938352Z","parent_msg_id":"1ad68c0f-7b2f-4d8e-8187-311bd132bf31"},"text/plain":"StatementMeta(, 30d65c52-cdfb-4f6f-a705-6779cd0f2222, 8, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Data successfully saved to /lakehouse/default/Files/2025-02-18_earthquake_data.json\n"]}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d38db068-e635-46b9-9271-d6828fcc892f"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ac6d84c0-a09f-421f-9095-8921a4c289b7"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cceef624-f664-4fed-9b60-4cc21c1ae79c"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"synapse_widget":{"version":"0.1","state":{}},"dependencies":{"lakehouse":{"default_lakehouse":"771b4953-b849-4c50-b457-ed6c24a08957","known_lakehouses":[{"id":"771b4953-b849-4c50-b457-ed6c24a08957"}],"default_lakehouse_name":"earthquakes_lakehouse","default_lakehouse_workspace_id":"43f6ab90-1c1c-4233-b673-0dae1c952751"}}},"nbformat":4,"nbformat_minor":5}